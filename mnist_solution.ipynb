{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_solution.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPPbkA4e/GvvnuDelE8PcT3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rlempka/mnist/blob/master/mnist_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pWfsBsx4wgQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7243639-ccad-496c-e6b5-480062e2ef7c"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import reciprocal\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "# TensorFlow â‰¥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kuMB3id44n9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "929f1f25-14cd-4ce4-cf95-785468f61843"
      },
      "source": [
        "# First step is to get the mnist data\n",
        "# We will use the keras.datasets library to load mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To95m43H6S0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7578ea57-d98c-4e58-b22c-8c9c6b62ca99"
      },
      "source": [
        "# Note that the data is already split into train and test datasets\n",
        "# Let's check the shape of our data\n",
        "\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "print(\"Training labels shape:\", y_train.shape)\n",
        "print(\"Testing data sahpe:\", X_test.shape)\n",
        "print(\"Testing labels shape:\", y_test.shape)\n",
        "\n",
        "# Normalize data\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape: (60000, 28, 28)\n",
            "Training labels shape: (60000,)\n",
            "Testing data sahpe: (10000, 28, 28)\n",
            "Testing labels shape: (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCV3Fmu36619",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8301f191-557d-473d-9460-1b3d213afe68"
      },
      "source": [
        "# Proportion of data allocated to testing is therefore\n",
        "print(\"{:.2f}%\".format((X_test.shape[0] / (X_train.shape[0] + X_test.shape[0]))*100))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x38m4_vbICz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# However because we want to use early stopping we will need to create a \n",
        "# validation set because this is how tensorflow determines early stopping\n",
        "\n",
        "# Note that our grid search will still use cross validation on the \n",
        "# training data that is not part of the validation set\n",
        "\n",
        "# The validation set will only be used at the end of each epoch\n",
        "\n",
        "# We use 10% of the training data to create validation sets\n",
        "\n",
        "X_valid, y_valid = X_train[:int(len(X_train)*.1)], y_train[:int(len(X_train)*.1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjSjhzdP7kyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will try three approaches to solving the mnist problem. Our goal is to see\n",
        "# if we can break 98% accuracy on the test set\n",
        "\n",
        "# Our approaches will be as follows\n",
        "\n",
        "# 1) Try using a simple MLP with a few hidden layers\n",
        "# 2) Try using a simple convnet\n",
        "\n",
        "# Let's start with the MLP\n",
        "# We will use the Sequential library from keras\n",
        "\n",
        "# We will define the model architecture in a function so that we can wrap\n",
        "# the function in an sklearn wrapper and perform randomized grid search to\n",
        "# tune hyperparameters\n",
        "\n",
        "def build_mnist_mlp(n_hidden=2, n_neurons=30, learning_rate=10e-3, \n",
        "                    input_shape=[28, 28], activation=\"relu\"):\n",
        "\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(keras.layers.Flatten())\n",
        "\n",
        "  for i in range(n_hidden):\n",
        "    model.add(keras.layers.Dense(n_neurons, activation = activation))\n",
        "  \n",
        "  # Note that this is the output layer for which we need 10 neurons\n",
        "  # to predict the 10 possible classes found in the MNIST dataset\n",
        "  model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "  optimizer= keras.optimizers.SGD(lr=learning_rate)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "\n",
        "mnist_mlp = keras.wrappers.scikit_learn.KerasClassifier(build_mnist_mlp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo08twA68Z2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's now create our parameter grid\n",
        "# This will be sampled from during our randomized parameter space search\n",
        "\n",
        "params = {\n",
        "    \"n_hidden\" : [1, 2, 3, 4],\n",
        "    \"n_neurons\" : [10, 20, 30, 40, 50],\n",
        "    \"learning_rate\" : [10e-5,10e-4,10e-3]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hly6rMvDAiTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note in the params distribution we sample from the reciprocal \n",
        "# distribution, the pdf is plotted below, note that the most likely\n",
        "# values are near 0 hence the learning rateis highly unlikely to\n",
        "# get larger than 0.01\n",
        "\n",
        "# Note the pdf of the reciprocal random variable is (1 / (x*log(b/a)))\n",
        "# For more information see the scipy documentation on scipy.stats.reciprocal\n",
        "\n",
        "# a, b = 3e-4, 3e-2\n",
        "# fig, ax = plt.subplots(1,1)\n",
        "# x = np.linspace(reciprocal.ppf(0.01, a, b),\n",
        "#                 reciprocal.ppf(0.99, a, b), 100)\n",
        "# ax.plot(x, reciprocal.pdf(x, a, b), 'r-', lw=5, alpha=0.6, label=\"reciprocal pdf\")\n",
        "\n",
        "# Due to an error this causes I have to change the values in the learning_rate\n",
        "# parameter search space to discrete values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3oyQeD2FJgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "adf8d0dc-2cf2-40cf-f9f7-cf0e4c011cd2"
      },
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"mnist_mlp.h5\") \n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(mnist_mlp, params,\n",
        "                                   n_iter=3, cv=3)\n",
        "rnd_search_cv.fit(X_train, y_train, epochs=50,\n",
        "                  validation_data = (X_valid, y_valid),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10), checkpoint_cb])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "40000/40000 [==============================] - 5s 134us/sample - loss: 2.3272 - accuracy: 0.0905 - val_loss: 2.3225 - val_accuracy: 0.0872\n",
            "Epoch 2/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.3167 - accuracy: 0.0934 - val_loss: 2.3131 - val_accuracy: 0.0938\n",
            "Epoch 3/50\n",
            "40000/40000 [==============================] - 3s 86us/sample - loss: 2.3083 - accuracy: 0.1014 - val_loss: 2.3051 - val_accuracy: 0.1048\n",
            "Epoch 4/50\n",
            "40000/40000 [==============================] - 3s 86us/sample - loss: 2.3009 - accuracy: 0.1134 - val_loss: 2.2979 - val_accuracy: 0.1195\n",
            "Epoch 5/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.2939 - accuracy: 0.1273 - val_loss: 2.2910 - val_accuracy: 0.1318\n",
            "Epoch 6/50\n",
            "40000/40000 [==============================] - 3s 87us/sample - loss: 2.2870 - accuracy: 0.1409 - val_loss: 2.2840 - val_accuracy: 0.1435\n",
            "Epoch 7/50\n",
            "40000/40000 [==============================] - 3s 87us/sample - loss: 2.2800 - accuracy: 0.1535 - val_loss: 2.2768 - val_accuracy: 0.1588\n",
            "Epoch 8/50\n",
            "40000/40000 [==============================] - 3s 85us/sample - loss: 2.2727 - accuracy: 0.1652 - val_loss: 2.2693 - val_accuracy: 0.1695\n",
            "Epoch 9/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 2.2651 - accuracy: 0.1772 - val_loss: 2.2615 - val_accuracy: 0.1795\n",
            "Epoch 10/50\n",
            "40000/40000 [==============================] - 3s 86us/sample - loss: 2.2571 - accuracy: 0.1898 - val_loss: 2.2532 - val_accuracy: 0.1923\n",
            "Epoch 11/50\n",
            "40000/40000 [==============================] - 3s 87us/sample - loss: 2.2486 - accuracy: 0.2031 - val_loss: 2.2443 - val_accuracy: 0.2038\n",
            "Epoch 12/50\n",
            "40000/40000 [==============================] - 3s 85us/sample - loss: 2.2393 - accuracy: 0.2149 - val_loss: 2.2348 - val_accuracy: 0.2127\n",
            "Epoch 13/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 2.2294 - accuracy: 0.2257 - val_loss: 2.2244 - val_accuracy: 0.2233\n",
            "Epoch 14/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 2.2185 - accuracy: 0.2360 - val_loss: 2.2130 - val_accuracy: 0.2315\n",
            "Epoch 15/50\n",
            "40000/40000 [==============================] - 3s 85us/sample - loss: 2.2066 - accuracy: 0.2459 - val_loss: 2.2006 - val_accuracy: 0.2415\n",
            "Epoch 16/50\n",
            "40000/40000 [==============================] - 3s 85us/sample - loss: 2.1935 - accuracy: 0.2555 - val_loss: 2.1868 - val_accuracy: 0.2532\n",
            "Epoch 17/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.1791 - accuracy: 0.2657 - val_loss: 2.1716 - val_accuracy: 0.2665\n",
            "Epoch 18/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.1632 - accuracy: 0.2788 - val_loss: 2.1547 - val_accuracy: 0.2797\n",
            "Epoch 19/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.1457 - accuracy: 0.2932 - val_loss: 2.1361 - val_accuracy: 0.2965\n",
            "Epoch 20/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 2.1264 - accuracy: 0.3071 - val_loss: 2.1157 - val_accuracy: 0.3175\n",
            "Epoch 21/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 2.1051 - accuracy: 0.3238 - val_loss: 2.0932 - val_accuracy: 0.3355\n",
            "Epoch 22/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 2.0818 - accuracy: 0.3433 - val_loss: 2.0687 - val_accuracy: 0.3575\n",
            "Epoch 23/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.0562 - accuracy: 0.3642 - val_loss: 2.0418 - val_accuracy: 0.3825\n",
            "Epoch 24/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.0282 - accuracy: 0.3851 - val_loss: 2.0124 - val_accuracy: 0.4050\n",
            "Epoch 25/50\n",
            "40000/40000 [==============================] - 3s 86us/sample - loss: 1.9975 - accuracy: 0.4059 - val_loss: 1.9803 - val_accuracy: 0.4243\n",
            "Epoch 26/50\n",
            "40000/40000 [==============================] - 3s 85us/sample - loss: 1.9640 - accuracy: 0.4250 - val_loss: 1.9454 - val_accuracy: 0.4455\n",
            "Epoch 27/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.9276 - accuracy: 0.4440 - val_loss: 1.9075 - val_accuracy: 0.4617\n",
            "Epoch 28/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.8882 - accuracy: 0.4605 - val_loss: 1.8665 - val_accuracy: 0.4802\n",
            "Epoch 29/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 1.8456 - accuracy: 0.4753 - val_loss: 1.8223 - val_accuracy: 0.4948\n",
            "Epoch 30/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.8000 - accuracy: 0.4908 - val_loss: 1.7750 - val_accuracy: 0.5085\n",
            "Epoch 31/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 1.7514 - accuracy: 0.5052 - val_loss: 1.7248 - val_accuracy: 0.5225\n",
            "Epoch 32/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 1.7001 - accuracy: 0.5202 - val_loss: 1.6721 - val_accuracy: 0.5347\n",
            "Epoch 33/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 1.6463 - accuracy: 0.5354 - val_loss: 1.6171 - val_accuracy: 0.5482\n",
            "Epoch 34/50\n",
            "40000/40000 [==============================] - 3s 85us/sample - loss: 1.5906 - accuracy: 0.5513 - val_loss: 1.5605 - val_accuracy: 0.5597\n",
            "Epoch 35/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 1.5334 - accuracy: 0.5689 - val_loss: 1.5026 - val_accuracy: 0.5777\n",
            "Epoch 36/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.4755 - accuracy: 0.5887 - val_loss: 1.4442 - val_accuracy: 0.5950\n",
            "Epoch 37/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.4172 - accuracy: 0.6111 - val_loss: 1.3860 - val_accuracy: 0.6185\n",
            "Epoch 38/50\n",
            "40000/40000 [==============================] - 3s 85us/sample - loss: 1.3592 - accuracy: 0.6343 - val_loss: 1.3277 - val_accuracy: 0.6412\n",
            "Epoch 39/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 1.3021 - accuracy: 0.6546 - val_loss: 1.2712 - val_accuracy: 0.6643\n",
            "Epoch 40/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.2463 - accuracy: 0.6763 - val_loss: 1.2158 - val_accuracy: 0.6858\n",
            "Epoch 41/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 1.1925 - accuracy: 0.6916 - val_loss: 1.1628 - val_accuracy: 0.7030\n",
            "Epoch 42/50\n",
            "40000/40000 [==============================] - 3s 86us/sample - loss: 1.1412 - accuracy: 0.7055 - val_loss: 1.1125 - val_accuracy: 0.7160\n",
            "Epoch 43/50\n",
            "40000/40000 [==============================] - 3s 86us/sample - loss: 1.0927 - accuracy: 0.7178 - val_loss: 1.0653 - val_accuracy: 0.7242\n",
            "Epoch 44/50\n",
            "40000/40000 [==============================] - 3s 85us/sample - loss: 1.0473 - accuracy: 0.7274 - val_loss: 1.0211 - val_accuracy: 0.7323\n",
            "Epoch 45/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 1.0052 - accuracy: 0.7357 - val_loss: 0.9802 - val_accuracy: 0.7407\n",
            "Epoch 46/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 0.9663 - accuracy: 0.7424 - val_loss: 0.9428 - val_accuracy: 0.7503\n",
            "Epoch 47/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 0.9306 - accuracy: 0.7493 - val_loss: 0.9085 - val_accuracy: 0.7560\n",
            "Epoch 48/50\n",
            "40000/40000 [==============================] - 3s 87us/sample - loss: 0.8980 - accuracy: 0.7543 - val_loss: 0.8771 - val_accuracy: 0.7618\n",
            "Epoch 49/50\n",
            "40000/40000 [==============================] - 4s 90us/sample - loss: 0.8681 - accuracy: 0.7604 - val_loss: 0.8483 - val_accuracy: 0.7677\n",
            "Epoch 50/50\n",
            "40000/40000 [==============================] - 4s 90us/sample - loss: 0.8409 - accuracy: 0.7638 - val_loss: 0.8220 - val_accuracy: 0.7715\n",
            "20000/20000 [==============================] - 1s 64us/sample - loss: 0.8409 - accuracy: 0.7620\n",
            "Train on 40000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "40000/40000 [==============================] - 4s 91us/sample - loss: 2.3195 - accuracy: 0.1161 - val_loss: 2.3142 - val_accuracy: 0.1148\n",
            "Epoch 2/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 2.3097 - accuracy: 0.1211 - val_loss: 2.3054 - val_accuracy: 0.1205\n",
            "Epoch 3/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 2.3018 - accuracy: 0.1274 - val_loss: 2.2979 - val_accuracy: 0.1282\n",
            "Epoch 4/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.2947 - accuracy: 0.1356 - val_loss: 2.2910 - val_accuracy: 0.1380\n",
            "Epoch 5/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 2.2881 - accuracy: 0.1451 - val_loss: 2.2842 - val_accuracy: 0.1488\n",
            "Epoch 6/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.2813 - accuracy: 0.1557 - val_loss: 2.2771 - val_accuracy: 0.1605\n",
            "Epoch 7/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.2743 - accuracy: 0.1671 - val_loss: 2.2697 - val_accuracy: 0.1720\n",
            "Epoch 8/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 2.2669 - accuracy: 0.1781 - val_loss: 2.2618 - val_accuracy: 0.1860\n",
            "Epoch 9/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.2591 - accuracy: 0.1896 - val_loss: 2.2533 - val_accuracy: 0.2007\n",
            "Epoch 10/50\n",
            "40000/40000 [==============================] - 3s 86us/sample - loss: 2.2506 - accuracy: 0.2005 - val_loss: 2.2442 - val_accuracy: 0.2108\n",
            "Epoch 11/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 2.2416 - accuracy: 0.2107 - val_loss: 2.2344 - val_accuracy: 0.2225\n",
            "Epoch 12/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.2318 - accuracy: 0.2211 - val_loss: 2.2237 - val_accuracy: 0.2355\n",
            "Epoch 13/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 2.2212 - accuracy: 0.2308 - val_loss: 2.2122 - val_accuracy: 0.2470\n",
            "Epoch 14/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 2.2096 - accuracy: 0.2419 - val_loss: 2.1996 - val_accuracy: 0.2570\n",
            "Epoch 15/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.1969 - accuracy: 0.2512 - val_loss: 2.1858 - val_accuracy: 0.2667\n",
            "Epoch 16/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.1829 - accuracy: 0.2612 - val_loss: 2.1706 - val_accuracy: 0.2747\n",
            "Epoch 17/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.1674 - accuracy: 0.2700 - val_loss: 2.1537 - val_accuracy: 0.2867\n",
            "Epoch 18/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 2.1502 - accuracy: 0.2794 - val_loss: 2.1349 - val_accuracy: 0.2962\n",
            "Epoch 19/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 2.1308 - accuracy: 0.2889 - val_loss: 2.1139 - val_accuracy: 0.3058\n",
            "Epoch 20/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 2.1092 - accuracy: 0.2990 - val_loss: 2.0904 - val_accuracy: 0.3170\n",
            "Epoch 21/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 2.0851 - accuracy: 0.3093 - val_loss: 2.0643 - val_accuracy: 0.3305\n",
            "Epoch 22/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.0581 - accuracy: 0.3237 - val_loss: 2.0352 - val_accuracy: 0.3440\n",
            "Epoch 23/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 2.0282 - accuracy: 0.3369 - val_loss: 2.0032 - val_accuracy: 0.3603\n",
            "Epoch 24/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.9953 - accuracy: 0.3521 - val_loss: 1.9680 - val_accuracy: 0.3745\n",
            "Epoch 25/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 1.9591 - accuracy: 0.3694 - val_loss: 1.9294 - val_accuracy: 0.3958\n",
            "Epoch 26/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 1.9196 - accuracy: 0.3901 - val_loss: 1.8873 - val_accuracy: 0.4160\n",
            "Epoch 27/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.8767 - accuracy: 0.4105 - val_loss: 1.8419 - val_accuracy: 0.4338\n",
            "Epoch 28/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 1.8305 - accuracy: 0.4339 - val_loss: 1.7932 - val_accuracy: 0.4565\n",
            "Epoch 29/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 1.7809 - accuracy: 0.4566 - val_loss: 1.7411 - val_accuracy: 0.4820\n",
            "Epoch 30/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.7279 - accuracy: 0.4812 - val_loss: 1.6856 - val_accuracy: 0.5040\n",
            "Epoch 31/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.6716 - accuracy: 0.5062 - val_loss: 1.6268 - val_accuracy: 0.5255\n",
            "Epoch 32/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 1.6122 - accuracy: 0.5286 - val_loss: 1.5650 - val_accuracy: 0.5458\n",
            "Epoch 33/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.5504 - accuracy: 0.5495 - val_loss: 1.5011 - val_accuracy: 0.5663\n",
            "Epoch 34/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.4868 - accuracy: 0.5695 - val_loss: 1.4360 - val_accuracy: 0.5870\n",
            "Epoch 35/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 1.4226 - accuracy: 0.5897 - val_loss: 1.3711 - val_accuracy: 0.6050\n",
            "Epoch 36/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 1.3595 - accuracy: 0.6068 - val_loss: 1.3079 - val_accuracy: 0.6248\n",
            "Epoch 37/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 1.2988 - accuracy: 0.6259 - val_loss: 1.2480 - val_accuracy: 0.6470\n",
            "Epoch 38/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 1.2416 - accuracy: 0.6428 - val_loss: 1.1920 - val_accuracy: 0.6665\n",
            "Epoch 39/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.1884 - accuracy: 0.6620 - val_loss: 1.1403 - val_accuracy: 0.6847\n",
            "Epoch 40/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 1.1393 - accuracy: 0.6799 - val_loss: 1.0929 - val_accuracy: 0.7028\n",
            "Epoch 41/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.0942 - accuracy: 0.6955 - val_loss: 1.0495 - val_accuracy: 0.7200\n",
            "Epoch 42/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 1.0529 - accuracy: 0.7112 - val_loss: 1.0095 - val_accuracy: 0.7287\n",
            "Epoch 43/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.0152 - accuracy: 0.7214 - val_loss: 0.9734 - val_accuracy: 0.7375\n",
            "Epoch 44/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 0.9806 - accuracy: 0.7300 - val_loss: 0.9400 - val_accuracy: 0.7492\n",
            "Epoch 45/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 0.9488 - accuracy: 0.7394 - val_loss: 0.9096 - val_accuracy: 0.7552\n",
            "Epoch 46/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 0.9195 - accuracy: 0.7447 - val_loss: 0.8813 - val_accuracy: 0.7633\n",
            "Epoch 47/50\n",
            "40000/40000 [==============================] - 3s 85us/sample - loss: 0.8925 - accuracy: 0.7519 - val_loss: 0.8554 - val_accuracy: 0.7693\n",
            "Epoch 48/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 0.8675 - accuracy: 0.7572 - val_loss: 0.8312 - val_accuracy: 0.7745\n",
            "Epoch 49/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 0.8442 - accuracy: 0.7634 - val_loss: 0.8092 - val_accuracy: 0.7773\n",
            "Epoch 50/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 0.8227 - accuracy: 0.7686 - val_loss: 0.7885 - val_accuracy: 0.7843\n",
            "20000/20000 [==============================] - 1s 58us/sample - loss: 0.8308 - accuracy: 0.7584\n",
            "Train on 40000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "40000/40000 [==============================] - 4s 90us/sample - loss: 2.2971 - accuracy: 0.1276 - val_loss: 2.2946 - val_accuracy: 0.1300\n",
            "Epoch 2/50\n",
            "40000/40000 [==============================] - 3s 86us/sample - loss: 2.2895 - accuracy: 0.1339 - val_loss: 2.2864 - val_accuracy: 0.1388\n",
            "Epoch 3/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 2.2818 - accuracy: 0.1419 - val_loss: 2.2782 - val_accuracy: 0.1463\n",
            "Epoch 4/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 2.2739 - accuracy: 0.1512 - val_loss: 2.2698 - val_accuracy: 0.1582\n",
            "Epoch 5/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 2.2657 - accuracy: 0.1593 - val_loss: 2.2609 - val_accuracy: 0.1683\n",
            "Epoch 6/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 2.2570 - accuracy: 0.1698 - val_loss: 2.2515 - val_accuracy: 0.1763\n",
            "Epoch 7/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 2.2477 - accuracy: 0.1787 - val_loss: 2.2416 - val_accuracy: 0.1887\n",
            "Epoch 8/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 2.2378 - accuracy: 0.1902 - val_loss: 2.2309 - val_accuracy: 0.2020\n",
            "Epoch 9/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 2.2270 - accuracy: 0.2015 - val_loss: 2.2193 - val_accuracy: 0.2110\n",
            "Epoch 10/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 2.2153 - accuracy: 0.2133 - val_loss: 2.2066 - val_accuracy: 0.2252\n",
            "Epoch 11/50\n",
            "40000/40000 [==============================] - 3s 80us/sample - loss: 2.2024 - accuracy: 0.2275 - val_loss: 2.1926 - val_accuracy: 0.2365\n",
            "Epoch 12/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 2.1881 - accuracy: 0.2448 - val_loss: 2.1772 - val_accuracy: 0.2585\n",
            "Epoch 13/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 2.1723 - accuracy: 0.2674 - val_loss: 2.1601 - val_accuracy: 0.2888\n",
            "Epoch 14/50\n",
            "40000/40000 [==============================] - 3s 86us/sample - loss: 2.1548 - accuracy: 0.2947 - val_loss: 2.1411 - val_accuracy: 0.3090\n",
            "Epoch 15/50\n",
            "40000/40000 [==============================] - 3s 84us/sample - loss: 2.1353 - accuracy: 0.3187 - val_loss: 2.1199 - val_accuracy: 0.3263\n",
            "Epoch 16/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.1136 - accuracy: 0.3350 - val_loss: 2.0965 - val_accuracy: 0.3402\n",
            "Epoch 17/50\n",
            "40000/40000 [==============================] - 3s 83us/sample - loss: 2.0895 - accuracy: 0.3458 - val_loss: 2.0705 - val_accuracy: 0.3487\n",
            "Epoch 18/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 2.0631 - accuracy: 0.3567 - val_loss: 2.0422 - val_accuracy: 0.3543\n",
            "Epoch 19/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 2.0341 - accuracy: 0.3664 - val_loss: 2.0111 - val_accuracy: 0.3605\n",
            "Epoch 20/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 2.0023 - accuracy: 0.3768 - val_loss: 1.9772 - val_accuracy: 0.3717\n",
            "Epoch 21/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 1.9678 - accuracy: 0.3879 - val_loss: 1.9404 - val_accuracy: 0.3850\n",
            "Epoch 22/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.9303 - accuracy: 0.4008 - val_loss: 1.9005 - val_accuracy: 0.3985\n",
            "Epoch 23/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 1.8897 - accuracy: 0.4127 - val_loss: 1.8575 - val_accuracy: 0.4127\n",
            "Epoch 24/50\n",
            "40000/40000 [==============================] - 3s 85us/sample - loss: 1.8460 - accuracy: 0.4287 - val_loss: 1.8111 - val_accuracy: 0.4365\n",
            "Epoch 25/50\n",
            "40000/40000 [==============================] - 3s 80us/sample - loss: 1.7990 - accuracy: 0.4485 - val_loss: 1.7614 - val_accuracy: 0.4563\n",
            "Epoch 26/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 1.7488 - accuracy: 0.4715 - val_loss: 1.7086 - val_accuracy: 0.4783\n",
            "Epoch 27/50\n",
            "40000/40000 [==============================] - 3s 79us/sample - loss: 1.6954 - accuracy: 0.4937 - val_loss: 1.6528 - val_accuracy: 0.4995\n",
            "Epoch 28/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.6392 - accuracy: 0.5128 - val_loss: 1.5944 - val_accuracy: 0.5250\n",
            "Epoch 29/50\n",
            "40000/40000 [==============================] - 3s 80us/sample - loss: 1.5805 - accuracy: 0.5360 - val_loss: 1.5338 - val_accuracy: 0.5477\n",
            "Epoch 30/50\n",
            "40000/40000 [==============================] - 3s 80us/sample - loss: 1.5201 - accuracy: 0.5572 - val_loss: 1.4718 - val_accuracy: 0.5685\n",
            "Epoch 31/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 1.4586 - accuracy: 0.5759 - val_loss: 1.4094 - val_accuracy: 0.5882\n",
            "Epoch 32/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 1.3967 - accuracy: 0.5946 - val_loss: 1.3468 - val_accuracy: 0.6045\n",
            "Epoch 33/50\n",
            "40000/40000 [==============================] - 3s 85us/sample - loss: 1.3354 - accuracy: 0.6130 - val_loss: 1.2854 - val_accuracy: 0.6227\n",
            "Epoch 34/50\n",
            "40000/40000 [==============================] - 3s 80us/sample - loss: 1.2754 - accuracy: 0.6310 - val_loss: 1.2257 - val_accuracy: 0.6433\n",
            "Epoch 35/50\n",
            "40000/40000 [==============================] - 3s 80us/sample - loss: 1.2176 - accuracy: 0.6499 - val_loss: 1.1687 - val_accuracy: 0.6653\n",
            "Epoch 36/50\n",
            "40000/40000 [==============================] - 3s 80us/sample - loss: 1.1625 - accuracy: 0.6686 - val_loss: 1.1146 - val_accuracy: 0.6832\n",
            "Epoch 37/50\n",
            "40000/40000 [==============================] - 3s 80us/sample - loss: 1.1106 - accuracy: 0.6850 - val_loss: 1.0640 - val_accuracy: 0.6995\n",
            "Epoch 38/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 1.0622 - accuracy: 0.6993 - val_loss: 1.0172 - val_accuracy: 0.7195\n",
            "Epoch 39/50\n",
            "40000/40000 [==============================] - 3s 82us/sample - loss: 1.0174 - accuracy: 0.7151 - val_loss: 0.9737 - val_accuracy: 0.7327\n",
            "Epoch 40/50\n",
            "40000/40000 [==============================] - 3s 81us/sample - loss: 0.9762 - accuracy: 0.7272 - val_loss: 0.9338 - val_accuracy: 0.7438\n",
            "Epoch 41/50\n",
            "40000/40000 [==============================] - 3s 85us/sample - loss: 0.9383 - accuracy: 0.7374 - val_loss: 0.8975 - val_accuracy: 0.7588\n",
            "Epoch 42/50\n",
            "40000/40000 [==============================] - 4s 90us/sample - loss: 0.9036 - accuracy: 0.7479 - val_loss: 0.8642 - val_accuracy: 0.7678\n",
            "Epoch 43/50\n",
            "35456/40000 [=========================>....] - ETA: 0s - loss: 0.8747 - accuracy: 0.7560"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpH0KiWqlCBq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnDe36zDlF7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_mnist_mlp_params = rnd_search_cv.best_params_\n",
        "\n",
        "print(\"Best params:\", best_mnist_mlp_params)\n",
        "print(\"Best score: {:.2f}%\".format(rnd_search_cv.best_score_*100))\n",
        "\n",
        "final_mnist_mlp = build_mnist_mlp(**best_mnist_mlp_params)\n",
        "\n",
        "# Note we use 150 epochs instead of 100 on our final model to attempt to improve\n",
        "# further\n",
        "\n",
        "history = final_mnist_mlp.fit(X_train, y_train, epochs=150, \n",
        "                              validation_data=(X_valid, y_valid),\n",
        "                        callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoPAT9RqsAqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the final mnist model\n",
        "\n",
        "final_mnist_mlp.save(\"final_mnist_mlp.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIgH0XuXTcMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Now let's build our convolutional neural network\n",
        "\n",
        "# We will use the keras sequential API\n",
        "\n",
        "# The architecutre will be simple with the following design\n",
        "# Input -> (Conv -> Relu -> Pool)*N -> FC\n",
        "# Or Input -> (Conv -> Relu)*N -> FC\n",
        "# Where N specifies the number of time the layer pattern within\n",
        "# the parenthesis is repeated\n",
        "\n",
        "# Note that although the general pattern will repeat we will tend to\n",
        "# reduce spatial dimensions and increase the depth of our network\n",
        "# as we move towards the FC (i.e. output) layer\n",
        "\n",
        "\n",
        "\n",
        "def build_mnist_convnet(input_shape=[28,28, 1], kernel_size=2, strides=(1,1),\n",
        "                        activation='relu', num_layers=3, pool_layer=True,\n",
        "                        padding=\"same\", dropout=False, \n",
        "                        learning_rate=10e-4):\n",
        " \n",
        "  model = keras.models.Sequential()\n",
        "  current_filter_size = 32\n",
        "  \n",
        "  # Note that we have the kernel size as 4 for the first conv layer\n",
        "  # instead of 2 to capture a larger set of the spatial dimension\n",
        "  # in the first layer\n",
        "  model.add(keras.layers.Conv2D(current_filter_size, 4, activation=activation, \n",
        "                                input_shape=input_shape, padding=padding))\n",
        "  for i in range(num_layers):\n",
        "    # increase depth of network by a factor of two every layer\n",
        "    current_filter_size *= 2\n",
        "    model.add(keras.layers.Conv2D(current_filter_size, kernel_size, \n",
        "                                  activation=activation, padding=padding))\n",
        "    if pool_layer:\n",
        "      model.add(keras.layers.MaxPooling2D(2))\n",
        "  \n",
        "  # Architecture at the end of the network flattens output from final pool\n",
        "  # or conv layer above and then connects to a dense network with two hidden\n",
        "  # layers\n",
        "\n",
        "  # Depth is now reduced by a factor of 2 until the final output layer of 10\n",
        "  # neurons is reached\n",
        "\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dense(128, activation=activation))\n",
        "  if dropout:\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "  model.add(keras.layers.Dense(64, activation=activation))\n",
        "  if dropout:\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "  model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "  optimizer= keras.optimizers.SGD(lr=learning_rate)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "convnet_mnist = keras.wrappers.scikit_learn.KerasClassifier(build_mnist_convnet)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OprqtBzad65Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnet_params = {\n",
        "    \"num_layers\" : [1, 2, 3, 4],\n",
        "    \"dropout\" : [True, False],\n",
        "    \"learning_rate\" : [10e-4,10e-3, 10e-2]\n",
        "\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YphDH7C_gjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keras expects a depth dimension for the matrices hence we need to rehsape\n",
        "# so that each instance is [28,28,1] instead of [28,28]\n",
        "\n",
        "X_train_conv = X_train.reshape(-1, 28, 28, 1)\n",
        "X_valid_conv = X_valid.reshape(-1, 28, 28, 1)\n",
        "X_test_conv = X_test.reshape(-1, 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhC2OUoXfDmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"mnist_mlp.h5\") \n",
        "\n",
        "\n",
        "rnd_search_conv_cv = RandomizedSearchCV(convnet_mnist, cnet_params,\n",
        "                                   n_iter=5, cv=2)\n",
        "\n",
        "# To save time I am going to lower the epochs from 100 to 20 here and we will\n",
        "# train on a higher number of epochs based on the best params\n",
        "\n",
        "# Also we've trained cv to 2\n",
        "\n",
        "rnd_search_conv_cv.fit(X_train_conv, y_train, epochs=20,\n",
        "                  validation_data = (X_valid_conv, y_valid),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10), \n",
        "                             checkpoint_cb,\n",
        "                             keras.callbacks.TensorBoard('./')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi_g7_F9O1RD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_convnet_params = rnd_search_conv_cv.best_params_\n",
        "\n",
        "print(\"Best convnet params: \", best_convnet_parms)\n",
        "print(\"Best score {:.2f}\".format(rnd_search_conv_cv.best_score_*100))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}